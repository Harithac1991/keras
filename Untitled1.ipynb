{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "from keras.layers import Input, Dense\n",
    "from keras.models import Model\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['C:\\\\Users\\\\haritha.c\\\\AppData\\\\Local\\\\Continuum\\\\anaconda2\\\\envs\\\\py36_tf\\\\lib\\\\site-packages\\\\ipykernel_launcher.py',\n",
       " '-f',\n",
       " 'C:\\\\Users\\\\haritha.c\\\\AppData\\\\Roaming\\\\jupyter\\\\runtime\\\\kernel-a1dafed7-c7e0-40fb-bf43-24c50578096d.json']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sys.argv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-f\n",
      "C:\\Users\\haritha.c\\AppData\\Roaming\\jupyter\\runtime\\kernel-a1dafed7-c7e0-40fb-bf43-24c50578096d.json\n"
     ]
    }
   ],
   "source": [
    "for i in sys.argv[1:]:\n",
    "    print (i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "filelist= [file for file in os.listdir('images/1024/') if file.endswith('.png')]\n",
    "chest_image_Sample = Image.open(\"images/1024/\"+filelist[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "images/1024/00000001_001.png\n",
      "PNG\n",
      "Portable network graphics\n",
      "(1024, 1024)\n",
      "L\n"
     ]
    }
   ],
   "source": [
    "print(chest_image_Sample.filename)\n",
    "print(chest_image_Sample.format)\n",
    "print(chest_image_Sample.format_description)\n",
    "print(chest_image_Sample.size)\n",
    "print(chest_image_Sample.mode)\n",
    "\n",
    "# print(chest_image_Sample.getcolors())\n",
    "# print(chest_image_Sample.histogram())\n",
    "# print(chest_image_Sample.show())\n",
    "# print(chest_image_Sample.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# to .bmp image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filelist= [file for file in os.listdir('images/1024_to_500/') if file.endswith('.png')]\n",
    "# infile_path = \"images/1024_to_500/\"\n",
    "# outfile_path = \"images/500_to_binary/\"\n",
    "# for i in filelist:\n",
    "#     Image.open(infile_path+i).save(outfile_path+str(i)+\".bmp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "for file in os.listdir('images/500_to_binary/'):\n",
    "    if file.endswith(\".bmp\"):\n",
    "        pass\n",
    "    else:\n",
    "        print(\"Failure : \",file )\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['.ipynb_checkpoints',\n",
       " 'AIinLS.xlsx',\n",
       " 'checkpoints',\n",
       " 'Convolutional-Autoencoder-master',\n",
       " 'Convolutional-Autoencoder-master.zip',\n",
       " 'Data_Entry_2017',\n",
       " 'Data_Entry_2017.csv.zip',\n",
       " 'icons',\n",
       " 'images',\n",
       " 'images_001.zip',\n",
       " 'keras',\n",
       " 'Readme.docx',\n",
       " 'Risk Analytics_ v4 - IA use cases.pptx',\n",
       " 'Untitled.ipynb',\n",
       " 'Untitled1.ipynb']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "filelist= [file for file in os.listdir('images/500_to_binary/') if file.endswith('.bmp')]\n",
    "chest_image_Sample = Image.open(\"images/500_to_binary/\"+filelist[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ True, False,  True, ...,  True,  True, False],\n",
       "       [ True,  True,  True, ..., False,  True,  True],\n",
       "       [False,  True,  True, ...,  True,  True, False],\n",
       "       ...,\n",
       "       [ True, False,  True, ..., False, False, False],\n",
       "       [False, False, False, ..., False, False, False],\n",
       "       [False,  True, False, ..., False, False, False]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(chest_image_Sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tqdm for a progress bar when loading the dataset\n",
    "# from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 500, 500, 1)\n",
      "(500, 500, 1)\n"
     ]
    }
   ],
   "source": [
    "datafolder = \"images/500_to_binary/\"\n",
    "filelist= [file for file in os.listdir('images/500_to_binary/') if file.endswith('.bmp')]\n",
    "training_data = []\n",
    "for filename in (filelist[:100]):\n",
    "#     print(filename)\n",
    "    #Combines folder name and file name.\n",
    "    path = os.path.join(datafolder,filename)\n",
    "    #Opens an image as an Image object.\n",
    "    image = Image.open(path)\n",
    "#     print(image.size)\n",
    "    #Resizes to a desired size.\n",
    "    image = image.resize((500,500))\n",
    "    #Creates an array of pixel values from the image.\n",
    "    pixel_array = np.asarray(image)\n",
    "    training_data.append(pixel_array)\n",
    "\n",
    "    #training_data is converted to a numpy array\n",
    "training_data = np.reshape(training_data,newshape=(-1,500,500,1))\n",
    "print(training_data.shape)\n",
    "print(training_data[0].shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training_data[0][0]\n",
    "train_flat = training_data.reshape(len(training_data),np.prod(training_data.shape[1:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 250000)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "train_flat.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recheck the image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(500, 500)\n"
     ]
    }
   ],
   "source": [
    "# import logging\n",
    "# logging.basicConfig(level=logging.DEBUG)\n",
    "# import matplotlib\n",
    "# print('Version', matplotlib.__version__)\n",
    "# import matplotlib.pyplot as plt\n",
    "dat = ((train_flat[0].reshape(500,500)))\n",
    "print(dat.shape)\n",
    "# plt.imshow(dat)\n",
    "# plt.show()\n",
    "img = Image.fromarray(dat, 'L')\n",
    "img.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building autoencoders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Input, Dense\n",
    "from keras.models import Model\n",
    "\n",
    "encoding_dim = [32]\n",
    "input_dim= train_flat.shape[1]\n",
    "#input placeholder\n",
    "input_image = Input(shape=(input_dim,))\n",
    "print(input_image)\n",
    "\n",
    "#encoded image placeholder\n",
    "encoded = Dense(encoding_dim[0], activation= \"relu\")(input_image)\n",
    "print(encoded.shape)\n",
    "\n",
    "#decoder\n",
    "decoded = Dense(input_dim,activation = \"sigmoid\")(encoded)\n",
    "print(decoded.shape)\n",
    "\n",
    "# feeding in inputs to model\n",
    "auto_en = Model(input_image, encoded)\n",
    "\n",
    "##Encoder\n",
    "encoder_module = Model(input_image, encoded)\n",
    "encoded_input = Input(shape=(encoding_dim[0],))\n",
    "\n",
    "print(auto_en.layers[1])\n",
    "#output of decoder\n",
    "decoder_layer = auto_en.layers[-1]\n",
    "\n",
    "#Building the Decoder module\n",
    "decoder = Model(encoded,decoder_layer(encoded))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sequential apis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Input,Dense\n",
    "from keras.models import Model,Sequential\n",
    "encoding_dim = 32\n",
    "input_dim = train_flat.shape[1]\n",
    "compression_factor = float(input_dim)/encoding_dim\n",
    "print(\"compression_factor : \",compression_factor)\n",
    "auto_encoder = Sequential()\n",
    "auto_encoder.add(Dense(encoding_dim,input_shape=(input_dim,),activation = \"relu\"))\n",
    "auto_encoder.add(Dense(input_dim,activation = \"relu\"))\n",
    "auto_encoder.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auto_encoder.compile(optimizer=\"adam\", loss = \"binary_crossentropy\")\n",
    "auto_encoder.fit(train_flat,train_flat,\n",
    "                epochs=20,\n",
    "                batch_size=256,\n",
    "                shuffle=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Original\n",
    "dat = ((train_flat[0].reshape(500,500)))\n",
    "print(dat.shape)\n",
    "img = Image.fromarray(dat, 'L')\n",
    "img.show()\n",
    "\n",
    "\n",
    "dat_to_pred = ((train_flat[0].reshape(-1, input_dim)))\n",
    "print(dat_to_pred.shape)\n",
    "predicted = auto_encoder.predict(dat_to_pred)\n",
    "predicted = ((predicted.reshape(500,500)))\n",
    "img = Image.fromarray(predicted, 'L')\n",
    "img.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# with encoder decoder split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compression_factor :  7812.5\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Input,Dense\n",
    "from keras.models import Model,Sequential\n",
    "encoding_dim = 32\n",
    "input_dim = train_flat.shape[1]\n",
    "compression_factor = float(input_dim)/encoding_dim\n",
    "print(\"compression_factor : \",compression_factor)\n",
    "auto_encoder = Sequential()\n",
    "auto_encoder.add(Dense(encoding_dim,input_shape=(input_dim,),activation = \"relu\"))\n",
    "auto_encoder.add(Dense(input_dim,activation = \"relu\"))\n",
    "# auto_encoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1c360434cc0>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "#encoder\n",
    "input_img = Input(shape=(input_dim,))\n",
    "encoder_layer = auto_encoder.layers[0]\n",
    "encoder = Model(input_img, encoder_layer(input_img))\n",
    "\n",
    "#secoder\n",
    "# create a placeholder for an encoded (32-dimensional) input\n",
    "encoded_output = Input(shape=(encoding_dim,))\n",
    "decoder_layer = auto_encoder.layers[1]\n",
    "decoder = Model(encoded_output, decoder_layer(encoded_output))\n",
    "\n",
    "auto_encoder.compile(optimizer=\"adam\", loss = \"binary_crossentropy\")\n",
    "auto_encoder.fit(train_flat,train_flat,\n",
    "                epochs=1,\n",
    "                batch_size=256,\n",
    "                shuffle=True,verbose=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[False,  True,  True, ..., False, False, False],\n",
       "       [ True, False,  True, ..., False, False, False],\n",
       "       [ True,  True,  True, ..., False, False, False],\n",
       "       ...,\n",
       "       [ True,  True,  True, ..., False, False, False],\n",
       "       [ True,  True,  True, ..., False, False, False],\n",
       "       [ True,  True,  True, ..., False, False, False]])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_flat[0].reshape(500, 500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 250000)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Original\n",
    "img = Image.fromarray(((train_flat[0].reshape(500, 500))), 'L')\n",
    "img.show()\n",
    "\n",
    "dat = ((train_flat[0].reshape(-1, input_dim)))\n",
    "print(dat.shape)\n",
    "encoded_imgs = encoder.predict(dat)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[93.657364, 83.37959 , 62.288254, 32.622932, 92.99345 , 92.3879  ,\n",
       "         0.      ,  0.      ,  0.      ,  0.      , 76.72613 , 84.329124,\n",
       "        81.33739 , 88.146065, 55.21419 ,  0.      ,  0.      ,  0.      ,\n",
       "        94.09247 , 83.67258 , 88.5243  , 91.748825, 90.2498  ,  0.      ,\n",
       "        90.151764, 94.196594, 83.36286 , 89.81024 , 69.05468 ,  0.      ,\n",
       "        92.9013  ,  0.      ]], dtype=float32)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_imgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('test',encoded_imgs)\n",
    "# import pickle as pkl\n",
    "# pkl.dump(encoded_imgs,\"test\")\n",
    "# import matplotlib.pyplot as plt\n",
    "# import matplotlib.cm as cm\n",
    "# import numpy as np\n",
    "# plt.imsave('filename.png', np.array(encoded_imgs).reshape(50,50), cmap=cm.gray)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.engine.training.Model at 0x1c360434b00>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[93.657364, 83.37959 , 62.288254, 32.622932, 92.99345 , 92.3879  ,\n",
       "         0.      ,  0.      ,  0.      ,  0.      , 76.72613 , 84.329124,\n",
       "        81.33739 , 88.146065, 55.21419 ,  0.      ,  0.      ,  0.      ,\n",
       "        94.09247 , 83.67258 , 88.5243  , 91.748825, 90.2498  ,  0.      ,\n",
       "        90.151764, 94.196594, 83.36286 , 89.81024 , 69.05468 ,  0.      ,\n",
       "        92.9013  ,  0.      ]], dtype=float32)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc_saved= np.load(\"test.npy\")\n",
    "enc_saved"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoded_imgs = decoder.predict(enc_saved)\n",
    "img = Image.fromarray(((decoded_imgs.reshape(500, 500))), 'L')\n",
    "img.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 32)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_imgs.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functional APIs - Not working\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Input, Dense\n",
    "from keras.models import Model\n",
    "\n",
    "encoding_dim = [1024, 512,32]\n",
    "#input placeholder\n",
    "input_image = Input(shape=(500,500))\n",
    "print(input_image)\n",
    "\n",
    "#encoded image placeholder\n",
    "encoded_1 = Dense(encoding_dim[0], activation= \"relu\")(input_image)\n",
    "encoded_2 = Dense(encoding_dim[1], activation= \"relu\")(encoded_1)\n",
    "encoded = Dense(encoding_dim[2], activation= \"relu\")(encoded_2)\n",
    "\n",
    "#decoder\n",
    "decoded_1 = Dense(encoding_dim[2],activation = \"relu\")(encoded)\n",
    "decoded_2 = Dense(encoding_dim[1],activation = \"relu\")(decoded_1)\n",
    "decoded = Dense(encoding_dim[0],activation = \"sigmoid\")(decoded_2)\n",
    "\n",
    "# feeding in inputs to model\n",
    "auto_en = Model(input_image, encoded)\n",
    "\n",
    "##Encoder\n",
    "encoder_module = Model(input_image, encoded)\n",
    "encoded_input = Input(shape=(encoding_dim[2],))\n",
    "\n",
    "\n",
    "#output of decoder\n",
    "decoder_layer = auto_en.layers[-1]\n",
    "\n",
    "#Building the Decoder module\n",
    "decoder = Model(encoded,decoder_layer(encoded))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing import image\n",
    "# image.load_img()\n",
    "train_datagen = image.ImageDataGenerator()\n",
    "training_set = train_datagen.flow_from_directory(directory=r\"./images/500_to_binary/\",\n",
    "                                                 target_size=(500, 500),\n",
    "                                                 color_mode=\"grayscale\",\n",
    "                                                 batch_size=32,\n",
    "                                                 class_mode=\"categorical\",\n",
    "                                                 shuffle=True,\n",
    "                                                 save_format= \".bmp\",\n",
    "                                                 seed=42)\n",
    "\n",
    "# training_image_array = np.array()\n",
    "# for i in filelist[1:100]:\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py36_tf",
   "language": "python",
   "name": "py36_tf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
