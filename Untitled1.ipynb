{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "from keras.layers import Input, Dense\n",
    "from keras.models import Model\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['C:\\\\Users\\\\haritha.c\\\\AppData\\\\Local\\\\Continuum\\\\anaconda2\\\\envs\\\\py36_tf\\\\lib\\\\site-packages\\\\ipykernel_launcher.py',\n",
       " '-f',\n",
       " 'C:\\\\Users\\\\haritha.c\\\\AppData\\\\Roaming\\\\jupyter\\\\runtime\\\\kernel-a1dafed7-c7e0-40fb-bf43-24c50578096d.json']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sys.argv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-f\n",
      "C:\\Users\\haritha.c\\AppData\\Roaming\\jupyter\\runtime\\kernel-a1dafed7-c7e0-40fb-bf43-24c50578096d.json\n"
     ]
    }
   ],
   "source": [
    "for i in sys.argv[1:]:\n",
    "    print (i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "filelist= [file for file in os.listdir('images/1024/') if file.endswith('.png')]\n",
    "chest_image_Sample = Image.open(\"images/1024/\"+filelist[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "images/1024/00000001_001.png\n",
      "PNG\n",
      "Portable network graphics\n",
      "(1024, 1024)\n",
      "L\n"
     ]
    }
   ],
   "source": [
    "print(chest_image_Sample.filename)\n",
    "print(chest_image_Sample.format)\n",
    "print(chest_image_Sample.format_description)\n",
    "print(chest_image_Sample.size)\n",
    "print(chest_image_Sample.mode)\n",
    "\n",
    "# print(chest_image_Sample.getcolors())\n",
    "# print(chest_image_Sample.histogram())\n",
    "# print(chest_image_Sample.show())\n",
    "# print(chest_image_Sample.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# to .bmp image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filelist= [file for file in os.listdir('images/1024_to_500/') if file.endswith('.png')]\n",
    "# infile_path = \"images/1024_to_500/\"\n",
    "# outfile_path = \"images/500_to_binary/\"\n",
    "# for i in filelist:\n",
    "#     Image.open(infile_path+i).save(outfile_path+str(i)+\".bmp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "for file in os.listdir('images/500_to_binary/'):\n",
    "    if file.endswith(\".bmp\"):\n",
    "        pass\n",
    "    else:\n",
    "        print(\"Failure : \",file )\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['.ipynb_checkpoints',\n",
       " 'AIinLS.xlsx',\n",
       " 'checkpoints',\n",
       " 'Convolutional-Autoencoder-master',\n",
       " 'Convolutional-Autoencoder-master.zip',\n",
       " 'Data_Entry_2017',\n",
       " 'Data_Entry_2017.csv.zip',\n",
       " 'icons',\n",
       " 'images',\n",
       " 'images_001.zip',\n",
       " 'keras',\n",
       " 'Readme.docx',\n",
       " 'Risk Analytics_ v4 - IA use cases.pptx',\n",
       " 'Untitled.ipynb',\n",
       " 'Untitled1.ipynb']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "filelist= [file for file in os.listdir('images/500_to_binary/') if file.endswith('.bmp')]\n",
    "chest_image_Sample = Image.open(\"images/500_to_binary/\"+filelist[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ True, False,  True, ...,  True,  True, False],\n",
       "       [ True,  True,  True, ..., False,  True,  True],\n",
       "       [False,  True,  True, ...,  True,  True, False],\n",
       "       ...,\n",
       "       [ True, False,  True, ..., False, False, False],\n",
       "       [False, False, False, ..., False, False, False],\n",
       "       [False,  True, False, ..., False, False, False]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(chest_image_Sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tqdm for a progress bar when loading the dataset\n",
    "# from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 500, 500, 1)\n",
      "(500, 500, 1)\n"
     ]
    }
   ],
   "source": [
    "datafolder = \"images/500_to_binary/\"\n",
    "filelist= [file for file in os.listdir('images/500_to_binary/') if file.endswith('.bmp')]\n",
    "training_data = []\n",
    "for filename in (filelist[:100]):\n",
    "#     print(filename)\n",
    "    #Combines folder name and file name.\n",
    "    path = os.path.join(datafolder,filename)\n",
    "    #Opens an image as an Image object.\n",
    "    image = Image.open(path)\n",
    "#     print(image.size)\n",
    "    #Resizes to a desired size.\n",
    "    image = image.resize((500,500))\n",
    "    #Creates an array of pixel values from the image.\n",
    "    pixel_array = np.asarray(image)\n",
    "    training_data.append(pixel_array)\n",
    "\n",
    "    #training_data is converted to a numpy array\n",
    "training_data = np.reshape(training_data,newshape=(-1,500,500,1))\n",
    "print(training_data.shape)\n",
    "print(training_data[0].shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training_data[0][0]\n",
    "train_flat = training_data.reshape(len(training_data),np.prod(training_data.shape[1:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 250000)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "train_flat.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recheck the image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(500, 500)\n"
     ]
    }
   ],
   "source": [
    "# import logging\n",
    "# logging.basicConfig(level=logging.DEBUG)\n",
    "# import matplotlib\n",
    "# print('Version', matplotlib.__version__)\n",
    "# import matplotlib.pyplot as plt\n",
    "dat = ((train_flat[0].reshape(500,500)))\n",
    "print(dat.shape)\n",
    "# plt.imshow(dat)\n",
    "# plt.show()\n",
    "img = Image.fromarray(dat, 'L')\n",
    "img.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building autoencoders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"input_69:0\", shape=(?, 250000), dtype=float32)\n",
      "(?, 32)\n",
      "<keras.layers.core.Dense object at 0x0000017996F587F0>\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Input 0 is incompatible with layer dense_77: expected axis -1 of input shape to have value 250000 but got shape (None, 32)",
     "output_type": "error",
     "traceback": [
      "---------------------------------------------------------------------------",
      "ValueError                                Traceback (most recent call last)",
      "<ipython-input-101-040367b346dc> in <module>\n     28 \n     29 #Building the Decoder module\n---> 30 decoder = Model(encoded,decoder_layer(encoded))\n",
      "~\\AppData\\Local\\Continuum\\anaconda2\\envs\\py36_tf\\lib\\site-packages\\keras\\engine\\base_layer.py in __call__(self, inputs, **kwargs)\n    438             # Raise exceptions in case the input is not compatible\n    439             # with the input_spec set at build time.\n--> 440             self.assert_input_compatibility(inputs)\n    441 \n    442             # Handle mask propagation.\n",
      "~\\AppData\\Local\\Continuum\\anaconda2\\envs\\py36_tf\\lib\\site-packages\\keras\\engine\\base_layer.py in assert_input_compatibility(self, inputs)\n    350                                 str(axis) + ' of input shape to have '\n    351                                 'value ' + str(value) +\n--> 352                                 ' but got shape ' + str(x_shape))\n    353             # Check shape.\n    354             if spec.shape is not None:\n",
      "ValueError: Input 0 is incompatible with layer dense_77: expected axis -1 of input shape to have value 250000 but got shape (None, 32)"
     ]
    }
   ],
   "source": [
    "from keras.layers import Input, Dense\n",
    "from keras.models import Model\n",
    "\n",
    "encoding_dim = [32]\n",
    "input_dim= train_flat.shape[1]\n",
    "#input placeholder\n",
    "input_image = Input(shape=(input_dim,))\n",
    "print(input_image)\n",
    "\n",
    "#encoded image placeholder\n",
    "encoded = Dense(encoding_dim[0], activation= \"relu\")(input_image)\n",
    "print(encoded.shape)\n",
    "\n",
    "#decoder\n",
    "decoded = Dense(input_dim,activation = \"sigmoid\")(encoded)\n",
    "\n",
    "\n",
    "# feeding in inputs to model\n",
    "auto_en = Model(input_image, encoded)\n",
    "\n",
    "##Encoder\n",
    "encoder_module = Model(input_image, encoded)\n",
    "encoded_input = Input(shape=(encoding_dim[0],))\n",
    "\n",
    "print(auto_en.layers[1])\n",
    "#output of decoder\n",
    "decoder_layer = auto_en.layers[-1]\n",
    "\n",
    "#Building the Decoder module\n",
    "decoder = Model(encoded,decoder_layer(encoded))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"input_45:0\", shape=(?, 500, 500), dtype=float32)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Input 0 is incompatible with layer dense_49: expected axis -1 of input shape to have value 512 but got shape (None, 500, 32)",
     "output_type": "error",
     "traceback": [
      "---------------------------------------------------------------------------",
      "ValueError                                Traceback (most recent call last)",
      "<ipython-input-58-1a39fcf9251f> in <module>\n     29 \n     30 #Building the Decoder module\n---> 31 decoder = Model(encoded,decoder_layer(encoded))\n",
      "~\\AppData\\Local\\Continuum\\anaconda2\\envs\\py36_tf\\lib\\site-packages\\keras\\engine\\base_layer.py in __call__(self, inputs, **kwargs)\n    438             # Raise exceptions in case the input is not compatible\n    439             # with the input_spec set at build time.\n--> 440             self.assert_input_compatibility(inputs)\n    441 \n    442             # Handle mask propagation.\n",
      "~\\AppData\\Local\\Continuum\\anaconda2\\envs\\py36_tf\\lib\\site-packages\\keras\\engine\\base_layer.py in assert_input_compatibility(self, inputs)\n    350                                 str(axis) + ' of input shape to have '\n    351                                 'value ' + str(value) +\n--> 352                                 ' but got shape ' + str(x_shape))\n    353             # Check shape.\n    354             if spec.shape is not None:\n",
      "ValueError: Input 0 is incompatible with layer dense_49: expected axis -1 of input shape to have value 512 but got shape (None, 500, 32)"
     ]
    }
   ],
   "source": [
    "from keras.layers import Input, Dense\n",
    "from keras.models import Model\n",
    "\n",
    "encoding_dim = [1024, 512,32]\n",
    "#input placeholder\n",
    "input_image = Input(shape=(500,500))\n",
    "print(input_image)\n",
    "\n",
    "#encoded image placeholder\n",
    "encoded_1 = Dense(encoding_dim[0], activation= \"relu\")(input_image)\n",
    "encoded_2 = Dense(encoding_dim[1], activation= \"relu\")(encoded_1)\n",
    "encoded = Dense(encoding_dim[2], activation= \"relu\")(encoded_2)\n",
    "\n",
    "#decoder\n",
    "decoded_1 = Dense(encoding_dim[2],activation = \"relu\")(encoded)\n",
    "decoded_2 = Dense(encoding_dim[1],activation = \"relu\")(decoded_1)\n",
    "decoded = Dense(encoding_dim[0],activation = \"sigmoid\")(decoded_2)\n",
    "\n",
    "# feeding in inputs to model\n",
    "auto_en = Model(input_image, encoded)\n",
    "\n",
    "##Encoder\n",
    "encoder_module = Model(input_image, encoded)\n",
    "encoded_input = Input(shape=(encoding_dim[2],))\n",
    "\n",
    "\n",
    "#output of decoder\n",
    "decoder_layer = auto_en.layers[-1]\n",
    "\n",
    "#Building the Decoder module\n",
    "decoder = Model(encoded,decoder_layer(encoded))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 0 images belonging to 0 classes.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing import image\n",
    "# image.load_img()\n",
    "train_datagen = image.ImageDataGenerator()\n",
    "training_set = train_datagen.flow_from_directory(directory=r\"./images/500_to_binary/\",\n",
    "                                                 target_size=(500, 500),\n",
    "                                                 color_mode=\"grayscale\",\n",
    "                                                 batch_size=32,\n",
    "                                                 class_mode=\"categorical\",\n",
    "                                                 shuffle=True,\n",
    "                                                 save_format= \".bmp\",\n",
    "                                                 seed=42)\n",
    "\n",
    "# training_image_array = np.array()\n",
    "# for i in filelist[1:100]:\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.preprocessing.image.ImageDataGenerator at 0x1fecda295f8>"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_datagen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py36_tf",
   "language": "python",
   "name": "py36_tf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
